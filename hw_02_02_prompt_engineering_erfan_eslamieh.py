# -*- coding: utf-8 -*-
"""HW_02_02_prompt engineering_Erfan Eslamieh

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pO58LRN3Bw7VI1JhGsl1cfNgZJP0joEy

***تمرین دوم با پرامپت به زبان فارسی***

***Second exercise with prompts in Persian***

**موضوع: "تفاوت حافظه‌ی کوتاه‌مدت و بلندمدت رو طوری توضیح بده که یه نوجوان متوجه بشه، لحن هم باید صمیمی و نوجوان‌پسند باشد**

**Topic: "Explain the difference between short-term and long-term memory in a way that a teenager can understand, and the tone should be friendly and teen-friendly**
"""

# Commented out IPython magic to ensure Python compatibility.
!pip install -q  langchain-openai langchain_community tiktoken langchain
# !pip install -q  langchain-cohere
# %pip install -qU langchain-google-genai

"""***Import Libraries***"""

import os
from langchain.prompts import PromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI

"""***If we use Open ai the code below can help us***"""

# import os
# from google.colab import userdata
# if "OPENAI_API_KEY" not in os.environ:

#     os.environ["OPENAI_API_KEY"] =  userdata.get('Openai_api_key')

# from langchain_openai import ChatOpenAI

# MODEL_NAME = "gpt-4o-mini"  # Ensure you use a valid OpenAI model name
# llm = ChatOpenAI(model_name=MODEL_NAME, temperature=0, max_tokens=512)

# print(f"Using model: {llm.model_name}")

from google.colab import userdata
if "GOOGLE_API_KEY" not in os.environ:
    os.environ["GOOGLE_API_KEY"] =  userdata.get('GOOGLE_API_KEY')

os.environ["GOOGLE_API_KEY"] = "AIzaSyBniRQ8VnJZVPGMdvImryK7R0NsAVSqxX0"

llm = ChatGoogleGenerativeAI(
    temperature=0,
    model="gemini-2.0-flash-exp"
)

"""***بخش اول: انتخاب موضوع و سبک نوشتاری***

---

***بخش دوم: اجرای پرامپت بدون Few-shot prompting***

***A normal zero shot model***
"""

Template_1 = ("""
تفاوت حافظه کوتاه‌مدت و حافظه بلندمدت را طوری توضیح بده که یک نوجوان بتواند بفهمد.""")

response = llm.invoke(Template_1)
print(response.content)

"""***متن بالا به دلایل زیر نتوانسته سبک مورد نظر ما که صمیمی و نوجوان پسند بود را به خوبی تقلید کند:***


1.   لحن متن نسبتاً رسمی و آموزشی است، نه خیلی خودمانی یا عامیانه مثل صحبت‌های نوجوانان.
2.   جملات واضح و دقیق‌اند، بدون استفاده از اصطلاحات خیلی محاوره‌ای یا شوخ‌طبعانه.
3. متن ساختارمند و مرتب است، بیشتر شبیه یک متن آموزشی کلاسیک تا یک گفتگوی دوستانه یا مکالمه روزمره.

---

***بخش سوم: اضافه کردن چند نمونه ی راهنما***

**اضافه کردن مدل few shot**
"""

Template_2 = """
مفاهیم علمی رو طوری توضیح بده که یه نوجوان بتونه راحت بفهمه، با زبان ساده و خودمونی، مثل مکالمه روزمره:

• حافظه‌ی رم گوشی؟ مثل یه میز کار کوچیکه؛ فقط چند تا چیز دم دستی رو روش می‌ذاری، ولی زود باید جمعشون کنی.
• حافظه‌ی هارد؟ مثل یه انباری بزرگه که همه‌چی رو برای همیشه نگه می‌داره، از خاطره تولد گرفته تا پسورد وای‌فای خونه!
• وقتی یه شماره تلفن رو فقط برای چند ثانیه حفظ می‌کنی تا واردش کنی؟ اون حافظه‌ی کوتاه‌مدته، سریع میاد و میره.
• وقتی هنوز اسم معلم کلاس اولت یادت هست؟ اون حافظه‌ی بلندمدته، چون یه جوری تو مغزت جا خوش کرده.

حالا، تفاوت کامل بین حافظه‌ی کوتاه‌مدت و بلندمدت رو هم توی همین سبک توضیح بده، طوری که یه نوجوان کامل بفهمه:
"""
response = llm.invoke(Template_2)
print(response.content)

"""**few shot prompting در قالب chat-based (با SystemMessage و HumanMessage)**"""

from langchain.schema import SystemMessage, HumanMessage
import os

os.environ["GOOGLE_API_KEY"] = "AIzaSyBniRQ8VnJZVPGMdvImryK7R0NsAVSqxX0"

llm = ChatGoogleGenerativeAI(
    temperature=0,
    model="gemini-2.0-flash-exp"
)

messages = [
    SystemMessage(
        content="""
تو یک معلم صمیمی، خلاق و شوخ هستی که مفاهیم پیچیده علمی رو برای نوجوان‌ها توضیح می‌دی.
همیشه از تشبیه‌های ساده، زبان خودمونی، و مثال‌های روزمره استفاده می‌کنی تا هر چیزی رو قابل فهم کنی.
"""
    ),
    HumanMessage(
        content="""
بیا چند تا مثال باحال و خودمونی برای توضیح حافظه بده، طوری که یه نوجوان کاملاً متوجه شه:

• حافظه‌ی رم گوشی؟ مثل یه میز کار کوچیکه؛ فقط چند تا چیز دم دستی رو روش می‌ذاری، ولی زود باید جمعشون کنی.
• حافظه‌ی هارد؟ مثل یه انباری بزرگه که همه‌چی رو برای همیشه نگه می‌داره، از خاطره تولد گرفته تا پسورد وای‌فای خونه!
• وقتی یه شماره تلفن رو فقط برای چند ثانیه حفظ می‌کنی تا واردش کنی؟ اون حافظه‌ی کوتاه‌مدته، سریع میاد و میره.
• وقتی هنوز اسم معلم کلاس اولت یادت هست؟ اون حافظه‌ی بلندمدته، چون یه جوری تو مغزت جا خوش کرده.

حالا همین سبک رو ادامه بده و تفاوت کامل بین حافظه‌ی کوتاه‌مدت و بلندمدت رو برام توضیح بده.
"""
    )
]

response = llm.invoke(messages)
print(response.content)

"""---

***بخش چهارم: مقایسه و تحلیل نتایج***

***1. حالت اول: Zero-shot Prompting***

در این حالت، از مدل خواسته شد تا تفاوت حافظه کوتاه‌مدت و بلندمدت را برای یک نوجوان توضیح دهد؛ بدون ارائه‌ی هیچ نمونه‌ی راهنمای سبکی یا محتوایی.

ویژگی‌های مشاهده‌شده:

لحن نسبتاً رسمی و توصیفی.

تلاش مدل برای ساده‌سازی مفاهیم مشخص بود اما به‌طور کامل با سبک نوجوانانه منطبق نبود.

مثال‌ها بیشتر توضیحی بودند تا داستان‌محور یا طنزآمیز.

نتیجه: مدل از نظر محتوا پاسخ دقیق و علمی ارائه داد، اما سبک انتخابی (زبان خودمانی و محاوره‌ای نوجوان‌پسند) را به‌خوبی تقلید نکرد.

***2. Few-shot Prompting - حالت اول (مثال‌های ساختار یافته در قالب دیالوگ)***

در این نسخه، پیش از درخواست اصلی، چند نمونه از توضیح‌های محاوره‌ای و ساده به مدل داده شد. نمونه‌ها شامل تشبیه‌هایی مانند «میز کار»، «کمد بایگانی»، و دیالوگ‌های روزمره (مثل مامان گفت دو تا نون بخر) بودند.

ویژگی‌های مشاهده‌شده:

لحن خروجی بسیار صمیمی‌تر و نوجوانانه‌تر از zero-shot شد.

مدل از مثال‌های خودمانی، ساده و تصویری استفاده کرد.

شوخ‌طبعی، لحن گفت‌وگویی و حتی اصطلاحات روزمره در خروجی مشاهده شد.

نتیجه: مدل سبک موردنظر را بهتر تقلید کرد و مثال‌هایی با قدرت تصویرسازی بالا ارائه داد. این نشان می‌دهد که حتی تعداد کمی نمونه می‌تواند سبک را به مدل آموزش دهد.

***3. Few-shot Prompting - حالت دوم (در قالب Chat-based: SystemMessage + HumanMessage)***

در این نسخه، همان نمونه‌های راهنما (میز کار، هارد دیسک، استوری اینستاگرام و...) در قالب پیام‌های چتی به مدل داده شد (با استفاده از SystemMessage و HumanMessage).

ویژگی‌های مشاهده‌شده:

ساختار مکالمه‌ای حفظ شد و مدل پاسخ را بسیار شبیه به سبک نمونه‌ها نوشت.

تنوع واژگان غیررسمی و کنایه‌ها بیشتر بود (مثلاً: کاغذ چرک‌نویس، قاب خاطره، آهنگ باحال).

خروجی حتی از نسخه‌ی قبلی هم محاوره‌ای‌تر شد.

نتیجه: قالب گفت‌وگویی باعث شد سبک غیررسمی و لحن نوجوانانه بهتر تثبیت شود. می‌توان گفت این نسخه، قوی‌ترین سبک‌سازی را در بین سه حالت داشت.

---

***خلاصه تحلیل:***

در حالت Zero-shot، مدل توضیح دقیق ولی رسمی و کمتر نوجوان‌پسند ارائه داد. با Few-shot ساده، مدل لحن خودمانی‌تر و مثال‌های روزمره بهتری داشت و ارتباط بهتری برقرار کرد. در قالب چتی (SystemMessage + HumanMessage) هم سبک به شکل طبیعی‌تر، روان‌تر و جذاب‌تر تقلید شد و خروجی بیشتر شبیه گفت‌وگو با یک دوست نوجوان بود.

در کل، افزودن چند نمونه راهنما به مدل کمک کرد سبک مورد نظر بهتر رعایت شود. اگر بخواهیم کیفیت و انسجام سبک بیشتر شود، اضافه کردن ۱ یا ۲ نمونه متنوع دیگر، مثلاً از دنیای بازی‌ها یا فضای مجازی، مفید خواهد بود.

---

**Second exercise with prompts in English**

**Part One: Choosing a Topic and Writing Style**

**Topic: "Explain the difference between short-term and long-term memory in a way that a teenager can understand, and the tone should be friendly and teen-friendly**

---

***Part Two: Running Prompts Without Few-shot Prompting***

***A normal zero shot model***
"""

Template_1 = ("""
Explain the difference between short-term memory and long-term memory in a way that a teenager would understand, don’t imitate the teen style too closely.
""")

response = llm.invoke(Template_1)
print(response.content)

"""***The model did not imitate the teen style very well. While the explanation is clear and somewhat friendly, it remains relatively general and neutral, lacking the distinct tone, slang, or playful phrasing that would strongly resonate with a teenager.***

---

**Part Three: Adding Some Guide Examples**

**Add a few shot model**
"""

Template_2 = """
Explain scientific concepts in a way that a teenager can easily understand — use casual, simple language, like a friendly everyday conversation:

• Phone's RAM? It's like a small desk — you only put a few things on it at once, and you have to clear it quickly.
• Hard drive? It's like a big storage room that keeps everything forever — from birthday memories to the Wi-Fi password!
• When you remember a phone number just long enough to type it in? That’s short-term memory — it comes and goes fast.
• When you still remember your first-grade teacher’s name? That’s long-term memory — it’s stuck deep in your brain.

Now, in the same style, explain the full difference between short-term and long-term memory so a teenager can totally get it:
"""
response = llm.invoke(Template_2)
print(response.content)

"""**Few shot prompting in chat-based format (with SystemMessage and HumanMessage)**"""

from langchain.schema import SystemMessage, HumanMessage
from langchain_google_genai import ChatGoogleGenerativeAI
import os

os.environ["GOOGLE_API_KEY"] = "AIzaSyBniRQ8VnJZVPGMdvImryK7R0NsAVSqxX0"

llm = ChatGoogleGenerativeAI(
    temperature=0,
    model="gemini-2.0-flash-exp"
)

messages = [
    SystemMessage(
        content="""
You're a friendly, creative, and humorous teacher who explains complex scientific concepts to teenagers.
You always use simple analogies, casual language, and real-life examples to make everything easy to understand.
"""
    ),
    HumanMessage(
        content="""
Give some fun and relatable examples to explain memory, in a way a teenager can totally understand:

• Phone's RAM? It's like a small desk — you only put a few things on it at once, and you have to clear it quickly.
• Hard drive? It's like a big storage room that keeps everything forever — from birthday memories to the Wi-Fi password!
• When you remember a phone number just long enough to type it in? That’s short-term memory — it comes and goes fast.
• When you still remember your first-grade teacher’s name? That’s long-term memory — it’s stuck deep in your brain.

Now, continue in the same style and explain the full difference between short-term and long-term memory.
"""
    )
]

response = llm.invoke(messages)
print(response.content)

"""**Part Four: Comparison and Analysis of Results**

**The zero-shot:** output provides a clear and informative explanation but sticks to a neutral, educational tone. Even though the prompt asked for a "teen-friendly" explanation, the model didn’t adopt a conversational or humorous style. This confirms the expectation: the model delivered a relatively general output without strongly imitating the desired tone.

**The standard few-shot prompt (with example phrases):** improved the tone considerably. The model began using more relatable metaphors, casual phrases, and daily examples, closer to how a teenager might talk. The teen-friendly style was much better imitated, showing the effectiveness of the examples.

**The chat-based few-shot format (SystemMessage + HumanMessage):** produced the most natural and vivid output. The tone was highly conversational, with slang, pop culture references (like “Snapchat” or “Pixar’s Inside Out”), and a friendly, playful teacher vibe. It matched the intended style very closely, even more than the standard few-shot prompt.

**Summary Analysis:**

In the zero-shot setting, the model gave a clear but formal explanation that lacked a teen-friendly tone. With the few-shot prompt, the language became more casual and relatable, using everyday examples. The chat-based few-shot approach worked best — the style felt more natural, like a fun conversation with a teenager.

Overall, giving examples helped the model better follow the intended tone. To make it even more engaging and consistent, adding 1–2 more varied examples (e.g., from gaming or social media) would be beneficial.
"""